{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1210b47a-8f51-44eb-a8ac-0b6c8c50a36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [07:21:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 906, number of negative: 1115\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 559\n",
      "[LightGBM] [Info] Number of data points in the train set: 2021, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.448293 -> initscore=-0.207570\n",
      "[LightGBM] [Info] Start training from score -0.207570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [07:22:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 724, number of negative: 892\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000431 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 554\n",
      "[LightGBM] [Info] Number of data points in the train set: 1616, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.448020 -> initscore=-0.208675\n",
      "[LightGBM] [Info] Start training from score -0.208675\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 725, number of negative: 892\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 553\n",
      "[LightGBM] [Info] Number of data points in the train set: 1617, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.448361 -> initscore=-0.207294\n",
      "[LightGBM] [Info] Start training from score -0.207294\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 725, number of negative: 892\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000253 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 558\n",
      "[LightGBM] [Info] Number of data points in the train set: 1617, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.448361 -> initscore=-0.207294\n",
      "[LightGBM] [Info] Start training from score -0.207294\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 725, number of negative: 892\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 552\n",
      "[LightGBM] [Info] Number of data points in the train set: 1617, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.448361 -> initscore=-0.207294\n",
      "[LightGBM] [Info] Start training from score -0.207294\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 725, number of negative: 892\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000416 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 553\n",
      "[LightGBM] [Info] Number of data points in the train set: 1617, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.448361 -> initscore=-0.207294\n",
      "[LightGBM] [Info] Start training from score -0.207294\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "MÃ©tricas:\n",
      "\n",
      "Accuracy: 93.08%\n",
      "Precision: 93.12%\n",
      "Recall: 92.74%\n",
      "F1-score: 92.91%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(self, n_estimators, criterion, max_depth, min_samples_split, min_samples_leaf, \n",
    "                 max_features, bootstrap, learning_rate, subsample, colsample_bytree, num_leaves, gamma,\n",
    "                 objective='binary:logistic', max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "                 min_weight_fraction_leaf=0.0, min_child_samples=20, feature_fraction=0.6,  metric='logloss'):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.max_features = max_features\n",
    "        self.bootstrap = bootstrap\n",
    "        self.random_state = 42\n",
    "        self.stacking_model = None  \n",
    "        self.predictions = []\n",
    "        self.learning_rate = learning_rate  \n",
    "        self.subsample = subsample  \n",
    "        self.colsample_bytree = colsample_bytree  \n",
    "        self.num_leaves = num_leaves\n",
    "        self.gamma = gamma\n",
    "        self.objective = objective\n",
    "        self.max_leaf_nodes = max_leaf_nodes\n",
    "        self.min_impurity_decrease = min_impurity_decrease\n",
    "        self.min_weight_fraction_leaf = min_weight_fraction_leaf\n",
    "        self.min_child_samples = min_child_samples\n",
    "        self.feature_fraction = feature_fraction\n",
    "        self.metric = metric\n",
    "\n",
    "    def fit(self, X, y):        \n",
    "        estimators = [\n",
    "            ('xgb', XGBClassifier(n_estimators=self.n_estimators, max_depth=self.max_depth, random_state=self.random_state,\n",
    "                                  learning_rate=self.learning_rate, subsample=self.subsample, colsample_bytree=self.colsample_bytree,\n",
    "                                  gamma=self.gamma, objective=self.objective, max_leaf_nodes=self.max_leaf_nodes,\n",
    "                                  min_impurity_decrease=self.min_impurity_decrease, min_weight_fraction_leaf=self.min_weight_fraction_leaf,\n",
    "                                  min_child_samples=self.min_child_samples, feature_fraction=self.feature_fraction,metric=self.metric)),\n",
    "            \n",
    "            ('lgbm', LGBMClassifier(n_estimators=self.n_estimators, max_depth=self.max_depth, random_state=self.random_state,\n",
    "                                    learning_rate=self.learning_rate, subsample=self.subsample, colsample_bytree=self.colsample_bytree,\n",
    "                                    num_leaves=self.num_leaves, max_leaf_nodes=self.max_leaf_nodes,\n",
    "                                    min_child_samples=self.min_child_samples, feature_fraction=self.feature_fraction)),\n",
    "            \n",
    "            ('extra_trees', ExtraTreesClassifier(n_estimators=self.n_estimators, criterion=self.criterion,\n",
    "                                                 max_depth=self.max_depth, min_samples_split=self.min_samples_split,\n",
    "                                                 min_samples_leaf=self.min_samples_leaf, max_features=self.max_features,\n",
    "                                                 bootstrap=self.bootstrap, random_state=self.random_state))]\n",
    "            \n",
    "        # Definir el clasificador de nivel 2 (modelo base)\n",
    "        rf_base = RandomForestClassifier(n_estimators=self.n_estimators, random_state=self.random_state)\n",
    "        \n",
    "        # Crear el modelo de stacking\n",
    "        self.stacking_model = StackingClassifier(estimators=estimators, final_estimator=rf_base)\n",
    "        self.stacking_model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.stacking_model.predict(X)\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {\n",
    "            'n_estimators': self.n_estimators,\n",
    "            'criterion': self.criterion,\n",
    "            'max_depth': self.max_depth,\n",
    "            'min_samples_split': self.min_samples_split,\n",
    "            'min_samples_leaf': self.min_samples_leaf,\n",
    "            'max_features': self.max_features,\n",
    "            'bootstrap': self.bootstrap,\n",
    "            'learning_rate': self.learning_rate,\n",
    "            'subsample': self.subsample,\n",
    "            'colsample_bytree': self.colsample_bytree,\n",
    "            'num_leaves': self.num_leaves,\n",
    "            'gamma': self.gamma,\n",
    "            'objective': self.objective,\n",
    "            'max_leaf_nodes': self.max_leaf_nodes,\n",
    "            'min_impurity_decrease': self.min_impurity_decrease,\n",
    "            'min_weight_fraction_leaf': self.min_weight_fraction_leaf,\n",
    "            'min_child_samples': self.min_child_samples,\n",
    "            'feature_fraction': self.feature_fraction,\n",
    "            'metric': self.metric\n",
    "        }\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        for param, value in params.items():\n",
    "            setattr(self, param, value)\n",
    "        return self\n",
    "\n",
    "\n",
    "class RandomForestClassifierWrapper:\n",
    "    def __init__(self, X, y, n_estimators, criterion, max_depth, min_samples_split,\n",
    "                 min_samples_leaf, max_features, bootstrap, learning_rate, subsample, colsample_bytree, num_leaves, gamma,\n",
    "                 objective='binary:logistic', max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "                 min_weight_fraction_leaf=0.0, min_child_samples=20, feature_fraction=0.6, metric='logloss'):\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        self.X_train = self.X_train.values\n",
    "        self.y_train = self.y_train.values\n",
    "        \n",
    "        self.rf = RandomForest(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth,\n",
    "                                min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf,\n",
    "                                max_features=max_features, bootstrap=bootstrap,\n",
    "                                learning_rate=learning_rate, subsample=subsample,\n",
    "                                colsample_bytree=colsample_bytree, num_leaves=num_leaves, gamma=gamma,\n",
    "                                objective=objective, max_leaf_nodes=max_leaf_nodes,\n",
    "                                min_impurity_decrease=min_impurity_decrease, min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "                                min_child_samples=min_child_samples, feature_fraction=feature_fraction,metric = metric)\n",
    "\n",
    "    def train(self):\n",
    "        self.rf.fit(self.X_train, self.y_train)\n",
    "        \n",
    "    def predict(self):\n",
    "        return self.rf.predict(self.X_test)\n",
    "\n",
    "    def evaluate(self):\n",
    "        y_pred = self.predict()        \n",
    "        accuracy = accuracy_score(self.y_test, y_pred)\n",
    "        precision = precision_score(self.y_test, y_pred, average='macro')\n",
    "        recall = recall_score(self.y_test, y_pred, average='macro')\n",
    "        f1 = f1_score(self.y_test, y_pred, average='macro')\n",
    "        return accuracy, precision, recall, f1\n",
    "\n",
    "    def paint_confusion_matrix(self):\n",
    "        # Calcular la matriz de confusiÃ³n\n",
    "        conf_matrix = confusion_matrix(self.y_test, self.predict())\n",
    "        \n",
    "        # Visualizar la matriz de confusiÃ³n\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(self.y_test), yticklabels=np.unique(self.y_test))\n",
    "        plt.xlabel('Predicted labels')\n",
    "        plt.ylabel('True labels')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "class Resultado:\n",
    "    def __init__(self, parametros):\n",
    "        self.parametros = parametros\n",
    "        self.metricas = {'Accuracy': None, 'Precision': None, 'Recall': None, 'F1-score': None}\n",
    "\n",
    "    def update_metrics(self, accuracy, precision, recall, f1_score):\n",
    "        self.metricas['Accuracy'] = accuracy\n",
    "        self.metricas['Precision'] = precision\n",
    "        self.metricas['Recall'] = recall\n",
    "        self.metricas['F1-score'] = f1_score\n",
    "        print(\"MÃ©tricas:\\n\")\n",
    "        for metrica, valor in self.metricas.items():\n",
    "            print(f\"{metrica}: {valor * 100:.2f}%\")\n",
    "        print(\"\\n\\n\\n\")\n",
    "        \n",
    "    \n",
    "\n",
    "def loadBalancedDataSet():\n",
    "    \"\"\"\n",
    "    Carga un conjunto de datos balanceado desde un archivo Excel.   \n",
    "    Returns:\n",
    "    - X (DataFrame): CaracterÃ­sticas del conjunto de datos.\n",
    "    - y (Series): Etiquetas del conjunto de datos.\n",
    "    \"\"\"\n",
    "     # Obtener la ruta del directorio actual\n",
    "    ruta_actual = os.getcwd()\n",
    "    # Concatenar el nombre del archivo al final de la ruta actual\n",
    "    archivo = os.path.join(ruta_actual, 'Balanced_Data_Set.xlsx')\n",
    "    # Cargar datos\n",
    "    df = pd.read_excel(archivo)\n",
    "    \n",
    "    #df = pd.read_excel(file_path)\n",
    "    X = df.drop('CONDUCTA', axis=1)\n",
    "    y = df['CONDUCTA']\n",
    "    return X, y\n",
    "\n",
    "def loadOptimizedParameters():\n",
    "    \"\"\"\n",
    "    Carga los parÃ¡metros optimizados desde un archivo Excel.\n",
    "    Returns:\n",
    "    - parametros (dict): ParÃ¡metros optimizados.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Obtener la ruta del directorio actual\n",
    "    ruta_actual = os.getcwd()\n",
    "    # Concatenar el nombre del archivo al final de la ruta actual\n",
    "    archivo = os.path.join(ruta_actual, 'ParametrosOptimizaciÃ³n.xlsx')\n",
    "    # Cargar datos\n",
    "    parametros_df = pd.read_excel(archivo)\n",
    "\n",
    "    #parametros_df = pd.read_excel(file_path)\n",
    "    fila = parametros_df.iloc[0]\n",
    "    parametros = dict(zip(parametros_df.columns, fila))\n",
    "    return parametros\n",
    "\n",
    "\n",
    "\n",
    "balanced_data_file = \"C:\\\\Users\\\\klgt1\\\\Downloads\\\\dataset_BALANCEADO.xlsx\"\n",
    "optimized_params_file = \"C:\\\\Users\\\\klgt1\\\\Downloads\\\\ParametrosOptimizaciÃ³n.xlsx\"\n",
    "\n",
    "X, y = loadBalancedDataSet()\n",
    "\n",
    "parametros = loadOptimizedParameters()\n",
    "\n",
    "# Ejecutar el clasificador con los parÃ¡metros actuales\n",
    "wrapper = RandomForestClassifierWrapper(X, y, **parametros)\n",
    "wrapper.train()\n",
    "\n",
    "# Obtener los resultados de print_metrics\n",
    "accuracy, precision, recall, f1_score = wrapper.evaluate()\n",
    "\n",
    "# Crear un objeto Resultado y actualizar sus mÃ©tricas\n",
    "resultado = Resultado(parametros)\n",
    "resultado.update_metrics(accuracy, precision, recall, f1_score)\n",
    "\n",
    "wrapper.paint_confusion_matrix()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
