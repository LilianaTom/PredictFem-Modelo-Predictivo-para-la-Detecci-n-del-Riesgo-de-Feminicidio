{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84060e3d-eb9b-479d-82f5-4433381287c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "\n",
    "# Clase para el clasificador RandomForest\n",
    "class RandomForest:\n",
    "    def __init__(self, n_estimators, criterion, max_depth, min_samples_split, min_samples_leaf, \n",
    "                 max_features, bootstrap, learning_rate, subsample, colsample_bytree, num_leaves, gamma,\n",
    "                 objective='binary:logistic', max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "                 min_weight_fraction_leaf=0.0, min_child_samples=20, feature_fraction=0.6, metric='logloss'):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.max_features = max_features\n",
    "        self.bootstrap = bootstrap\n",
    "        self.random_state = 42\n",
    "        self.stacking_model = None  \n",
    "        self.predictions = []\n",
    "        self.learning_rate = learning_rate  \n",
    "        self.subsample = subsample  \n",
    "        self.colsample_bytree = colsample_bytree  \n",
    "        self.num_leaves = num_leaves\n",
    "        self.gamma = gamma\n",
    "        self.objective = objective\n",
    "        self.max_leaf_nodes = max_leaf_nodes\n",
    "        self.min_impurity_decrease = min_impurity_decrease\n",
    "        self.min_weight_fraction_leaf = min_weight_fraction_leaf\n",
    "        self.min_child_samples = min_child_samples\n",
    "        self.feature_fraction = feature_fraction\n",
    "        self.metric = metric\n",
    "        self.models = []  # Lista para almacenar los árboles\n",
    "\n",
    "    def fit(self, X, y):        \n",
    "        # Definir el clasificador de nivel 1\n",
    "        estimators = [\n",
    "            ('xgb', XGBClassifier(n_estimators=self.n_estimators, max_depth=self.max_depth, random_state=self.random_state,\n",
    "                                  learning_rate=self.learning_rate, subsample=self.subsample, colsample_bytree=self.colsample_bytree,\n",
    "                                  gamma=self.gamma, objective=self.objective, max_leaf_nodes=self.max_leaf_nodes,\n",
    "                                  min_impurity_decrease=self.min_impurity_decrease, min_weight_fraction_leaf=self.min_weight_fraction_leaf,\n",
    "                                  min_child_samples=self.min_child_samples, feature_fraction=self.feature_fraction, metric=self.metric)),\n",
    "            \n",
    "            ('lgbm', LGBMClassifier(n_estimators=self.n_estimators, max_depth=self.max_depth, random_state=self.random_state,\n",
    "                                    learning_rate=self.learning_rate, subsample=self.subsample, colsample_bytree=self.colsample_bytree,\n",
    "                                    num_leaves=self.num_leaves, max_leaf_nodes=self.max_leaf_nodes,\n",
    "                                    min_child_samples=self.min_child_samples, feature_fraction=self.feature_fraction)),\n",
    "            \n",
    "            ('extra_trees', ExtraTreesClassifier(n_estimators=self.n_estimators, criterion=self.criterion,\n",
    "                                                 max_depth=self.max_depth, min_samples_split=self.min_samples_split,\n",
    "                                                 min_samples_leaf=self.min_samples_leaf, max_features=self.max_features,\n",
    "                                                 bootstrap=self.bootstrap, random_state=self.random_state))]\n",
    "            \n",
    "        # Definir el clasificador de nivel 2 (modelo base)\n",
    "        rf_base = RandomForestClassifier(n_estimators=self.n_estimators, random_state=self.random_state)\n",
    "        \n",
    "        # Crear el modelo de stacking\n",
    "        self.stacking_model = StackingClassifier(estimators=estimators, final_estimator=rf_base)\n",
    "        self.stacking_model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.stacking_model.predict(X)\n",
    "\n",
    "    def feature_importances(self, X, y):\n",
    "        self.fit(X, y)\n",
    "        importances = np.zeros(X.shape[1])\n",
    "        for tree in self.models:\n",
    "            importances += tree.feature_importances_\n",
    "        return importances / len(self.models)\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {\n",
    "            'n_estimators': self.n_estimators,\n",
    "            'criterion': self.criterion,\n",
    "            'max_depth': self.max_depth,\n",
    "            'min_samples_split': self.min_samples_split,\n",
    "            'min_samples_leaf': self.min_samples_leaf,\n",
    "            'max_features': self.max_features,\n",
    "            'bootstrap': self.bootstrap,\n",
    "            'learning_rate': self.learning_rate,\n",
    "            'subsample': self.subsample,\n",
    "            'colsample_bytree': self.colsample_bytree,\n",
    "            'num_leaves': self.num_leaves,\n",
    "            'gamma': self.gamma,\n",
    "            'objective': self.objective,\n",
    "            'max_leaf_nodes': self.max_leaf_nodes,\n",
    "            'min_impurity_decrease': self.min_impurity_decrease,\n",
    "            'min_weight_fraction_leaf': self.min_weight_fraction_leaf,\n",
    "            'min_child_samples': self.min_child_samples,\n",
    "            'feature_fraction': self.feature_fraction,\n",
    "            'metric': self.metric\n",
    "        }\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        for param, value in params.items():\n",
    "            setattr(self, param, value)\n",
    "        return self\n",
    "\n",
    "# Clase para envolver RandomForest y aplicar PCA\n",
    "\n",
    "class RandomForestClassifierWrapper:\n",
    "    def __init__(self, X, y, feature_names=None, **kwargs):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        self.feature_names = feature_names  \n",
    "        self.kwargs = kwargs\n",
    "        self.rf = RandomForest(**kwargs)\n",
    "        self.selected_features = None\n",
    "\n",
    "    def train(self):        \n",
    "        # Definir el pipeline con PCA y el clasificador RandomForest\n",
    "        pipeline = Pipeline([\n",
    "            ('pca', PCA()),\n",
    "            ('rf', self.rf)\n",
    "        ])\n",
    "    \n",
    "        # Definir los parámetros a ajustar en el grid search\n",
    "        param_grid = {\n",
    "            'pca__n_components': [10, 20, 30, 42]  # Rango de valores de n_components\n",
    "        }\n",
    "    \n",
    "        # Realizar la búsqueda en la grilla con validación cruzada\n",
    "        grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='precision')\n",
    "        grid_search.fit(self.X_train, self.y_train)\n",
    "    \n",
    "        # Obtener el mejor estimador (pipeline)\n",
    "        best_pipeline = grid_search.best_estimator_\n",
    "        self.rf = best_pipeline.named_steps['rf']\n",
    "    \n",
    "        # Obtener el mejor número de componentes principales (n_components)\n",
    "        best_n_components = best_pipeline.named_steps['pca'].n_components\n",
    "        print(\"\\n**********************Mejor número de componentes principales (n_components):\", best_n_components)\n",
    "    \n",
    "        # Aplicar PCA con el número óptimo de componentes\n",
    "        pca = PCA(n_components=best_n_components)\n",
    "        self.X_train = pca.fit_transform(self.X_train)\n",
    "        self.X_test = pca.transform(self.X_test)\n",
    "    \n",
    "        # Entrenar el modelo RandomForest con los datos transformados\n",
    "        self.rf.fit(self.X_train, self.y_train)\n",
    "    \n",
    "        # Obtener las características seleccionadas por PCA\n",
    "        selected_features = pca.components_\n",
    "        print(\"Características seleccionadas por PCA:\")\n",
    "        print(selected_features)\n",
    "    \n",
    "        # Si se proporcionan los nombres de las características, calcular la importancia de las características\n",
    "        if self.feature_names is not None:\n",
    "            importances = self.rf.feature_importances(self.X_train, self.y_train)\n",
    "            feature_importance = sorted(zip(self.feature_names, importances), key=lambda x: x[1], reverse=True)\n",
    "            self.selected_features = feature_importance\n",
    "            print(\"Características seleccionadas según su importancia para la precisión:\")\n",
    "            print(self.selected_features)\n",
    "\n",
    "\n",
    "    def evaluate(self):\n",
    "        y_pred = self.rf.predict(self.X_test)\n",
    "        accuracy = accuracy_score(self.y_test, y_pred)\n",
    "        precision = precision_score(self.y_test, y_pred, average='macro')\n",
    "        recall = recall_score(self.y_test, y_pred, average='macro')\n",
    "        f1 = f1_score(self.y_test, y_pred, average='macro')\n",
    "        return accuracy, precision, recall, f1\n",
    "\n",
    "    def print_selected_features(self):\n",
    "        if self.selected_features is not None:\n",
    "            print(\"Características seleccionadas según su importancia para la precisión:\")\n",
    "            for i, (feature, importance) in enumerate(self.selected_features):\n",
    "                print(f\"Característica {i+1}: {feature} - Importancia: {importance}\")\n",
    "        else:\n",
    "            print(\"No se han seleccionado características.\")\n",
    "\n",
    "# Leer datos\n",
    "df = pd.read_excel(\"C:\\\\Users\\\\klgt1\\\\Downloads\\\\dataset_BALANCEADO.xlsx\")\n",
    "X = df.drop('CONDUCTA', axis=1)\n",
    "y = df['CONDUCTA']\n",
    "feature_names = X.columns.tolist()  \n",
    "\n",
    "# Leer los parámetros desde el archivo Excel\n",
    "parametros_df = pd.read_excel(\"\\\\Users\\\\klgt1\\\\Downloads\\\\ParametrosOptimización.xlsx\")\n",
    "print(parametros_df)\n",
    "# Obtener el primer conjunto de parámetros\n",
    "parametros = parametros_df.iloc[0].to_dict()\n",
    "\n",
    "# Ejecutar el clasificador con los parámetros actuales\n",
    "wrapper = RandomForestClassifierWrapper(X, y, feature_names=feature_names, **parametros)\n",
    "wrapper.train()\n",
    "wrapper.print_selected_features()\n",
    "\n",
    "# Obtener los resultados\n",
    "accuracy, precision, recall, f1_score = wrapper.evaluate()\n",
    "\n",
    "# Imprimir métricas\n",
    "print(\"Métricas:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualizar la matriz de confusión\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda91a99-bd42-4ed6-939d-f0adb614c359",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
