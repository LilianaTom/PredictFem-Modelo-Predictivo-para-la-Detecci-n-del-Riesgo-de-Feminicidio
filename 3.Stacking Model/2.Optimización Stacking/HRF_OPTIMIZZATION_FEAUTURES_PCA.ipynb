{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda91a99-bd42-4ed6-939d-f0adb614c359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "747d9921-3c68-4343-8075-c9261cdf9f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esta ejecutando\n",
      "   n_estimators criterion  max_depth  min_samples_split  min_samples_leaf  \\\n",
      "0            50   entropy         20                  4                 1   \n",
      "\n",
      "  max_features  bootstrap  learning_rate  subsample  colsample_bytree  \\\n",
      "0         sqrt       True            0.1        0.8               0.8   \n",
      "\n",
      "   num_leaves  gamma   metric  min_impurity_decrease  feature_fraction  \\\n",
      "0          40      0  logloss                    0.1               0.6   \n",
      "\n",
      "   min_child_samples  min_weight_fraction_leaf        objective  \n",
      "0                 10                         0  binary:logistic  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 733, number of negative: 883\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 1616, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.453589 -> initscore=-0.186179\n",
      "[LightGBM] [Info] Start training from score -0.186179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 586, number of negative: 706\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000152 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 1292, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.453560 -> initscore=-0.186295\n",
      "[LightGBM] [Info] Start training from score -0.186295\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 587, number of negative: 706\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.453983 -> initscore=-0.184590\n",
      "[LightGBM] [Info] Start training from score -0.184590\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 587, number of negative: 706\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.453983 -> initscore=-0.184590\n",
      "[LightGBM] [Info] Start training from score -0.184590\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 586, number of negative: 707\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.453210 -> initscore=-0.187711\n",
      "[LightGBM] [Info] Start training from score -0.187711\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 586, number of negative: 707\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.453210 -> initscore=-0.187711\n",
      "[LightGBM] [Info] Start training from score -0.187711\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 735, number of negative: 882\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 1617, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.454545 -> initscore=-0.182322\n",
      "[LightGBM] [Info] Start training from score -0.182322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 588, number of negative: 705\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.454756 -> initscore=-0.181471\n",
      "[LightGBM] [Info] Start training from score -0.181471\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 588, number of negative: 705\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.454756 -> initscore=-0.181471\n",
      "[LightGBM] [Info] Start training from score -0.181471\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 588, number of negative: 706\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.454405 -> initscore=-0.182888\n",
      "[LightGBM] [Info] Start training from score -0.182888\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 588, number of negative: 706\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.454405 -> initscore=-0.182888\n",
      "[LightGBM] [Info] Start training from score -0.182888\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 588, number of negative: 706\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.454405 -> initscore=-0.182888\n",
      "[LightGBM] [Info] Start training from score -0.182888\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 720, number of negative: 897\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000243 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 1617, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445269 -> initscore=-0.219805\n",
      "[LightGBM] [Info] Start training from score -0.219805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:05] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:05] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:06] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 717\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445476 -> initscore=-0.218968\n",
      "[LightGBM] [Info] Start training from score -0.218968\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 717\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445476 -> initscore=-0.218968\n",
      "[LightGBM] [Info] Start training from score -0.218968\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 718\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445131 -> initscore=-0.220362\n",
      "[LightGBM] [Info] Start training from score -0.220362\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 718\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445131 -> initscore=-0.220362\n",
      "[LightGBM] [Info] Start training from score -0.220362\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 718\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445131 -> initscore=-0.220362\n",
      "[LightGBM] [Info] Start training from score -0.220362\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 716, number of negative: 901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 1617, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442795 -> initscore=-0.229825\n",
      "[LightGBM] [Info] Start training from score -0.229825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:06] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:07] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 573, number of negative: 720\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.443155 -> initscore=-0.228365\n",
      "[LightGBM] [Info] Start training from score -0.228365\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 572, number of negative: 721\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442382 -> initscore=-0.231500\n",
      "[LightGBM] [Info] Start training from score -0.231500\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 573, number of negative: 721\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442813 -> initscore=-0.229753\n",
      "[LightGBM] [Info] Start training from score -0.229753\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 573, number of negative: 721\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442813 -> initscore=-0.229753\n",
      "[LightGBM] [Info] Start training from score -0.229753\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 573, number of negative: 721\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000152 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442813 -> initscore=-0.229753\n",
      "[LightGBM] [Info] Start training from score -0.229753\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 720, number of negative: 897\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 1617, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445269 -> initscore=-0.219805\n",
      "[LightGBM] [Info] Start training from score -0.219805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:08] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:08] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 717\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445476 -> initscore=-0.218968\n",
      "[LightGBM] [Info] Start training from score -0.218968\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 717\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000208 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445476 -> initscore=-0.218968\n",
      "[LightGBM] [Info] Start training from score -0.218968\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 718\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445131 -> initscore=-0.220362\n",
      "[LightGBM] [Info] Start training from score -0.220362\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 718\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445131 -> initscore=-0.220362\n",
      "[LightGBM] [Info] Start training from score -0.220362\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 718\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445131 -> initscore=-0.220362\n",
      "[LightGBM] [Info] Start training from score -0.220362\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 733, number of negative: 883\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000464 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 1616, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.453589 -> initscore=-0.186179\n",
      "[LightGBM] [Info] Start training from score -0.186179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:09] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:10] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 586, number of negative: 706\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 1292, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.453560 -> initscore=-0.186295\n",
      "[LightGBM] [Info] Start training from score -0.186295\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 587, number of negative: 706\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.453983 -> initscore=-0.184590\n",
      "[LightGBM] [Info] Start training from score -0.184590\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 587, number of negative: 706\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000451 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.453983 -> initscore=-0.184590\n",
      "[LightGBM] [Info] Start training from score -0.184590\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 586, number of negative: 707\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000513 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.453210 -> initscore=-0.187711\n",
      "[LightGBM] [Info] Start training from score -0.187711\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 586, number of negative: 707\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000544 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.453210 -> initscore=-0.187711\n",
      "[LightGBM] [Info] Start training from score -0.187711\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 735, number of negative: 882\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000472 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 1617, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.454545 -> initscore=-0.182322\n",
      "[LightGBM] [Info] Start training from score -0.182322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:11] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:11] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:12] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 588, number of negative: 705\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.454756 -> initscore=-0.181471\n",
      "[LightGBM] [Info] Start training from score -0.181471\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 588, number of negative: 705\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000440 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.454756 -> initscore=-0.181471\n",
      "[LightGBM] [Info] Start training from score -0.181471\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 588, number of negative: 706\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000452 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.454405 -> initscore=-0.182888\n",
      "[LightGBM] [Info] Start training from score -0.182888\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 588, number of negative: 706\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000483 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.454405 -> initscore=-0.182888\n",
      "[LightGBM] [Info] Start training from score -0.182888\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 588, number of negative: 706\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.454405 -> initscore=-0.182888\n",
      "[LightGBM] [Info] Start training from score -0.182888\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 720, number of negative: 897\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 1617, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445269 -> initscore=-0.219805\n",
      "[LightGBM] [Info] Start training from score -0.219805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:13] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:13] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:14] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 717\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000431 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445476 -> initscore=-0.218968\n",
      "[LightGBM] [Info] Start training from score -0.218968\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 717\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445476 -> initscore=-0.218968\n",
      "[LightGBM] [Info] Start training from score -0.218968\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 718\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000451 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445131 -> initscore=-0.220362\n",
      "[LightGBM] [Info] Start training from score -0.220362\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 718\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445131 -> initscore=-0.220362\n",
      "[LightGBM] [Info] Start training from score -0.220362\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 718\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000449 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445131 -> initscore=-0.220362\n",
      "[LightGBM] [Info] Start training from score -0.220362\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 716, number of negative: 901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000506 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 1617, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442795 -> initscore=-0.229825\n",
      "[LightGBM] [Info] Start training from score -0.229825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:14] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:15] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 573, number of negative: 720\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000472 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.443155 -> initscore=-0.228365\n",
      "[LightGBM] [Info] Start training from score -0.228365\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 572, number of negative: 721\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000445 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442382 -> initscore=-0.231500\n",
      "[LightGBM] [Info] Start training from score -0.231500\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 573, number of negative: 721\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000521 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442813 -> initscore=-0.229753\n",
      "[LightGBM] [Info] Start training from score -0.229753\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 573, number of negative: 721\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000431 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442813 -> initscore=-0.229753\n",
      "[LightGBM] [Info] Start training from score -0.229753\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 573, number of negative: 721\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000519 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442813 -> initscore=-0.229753\n",
      "[LightGBM] [Info] Start training from score -0.229753\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 720, number of negative: 897\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 1617, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445269 -> initscore=-0.219805\n",
      "[LightGBM] [Info] Start training from score -0.219805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:16] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:17] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 717\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445476 -> initscore=-0.218968\n",
      "[LightGBM] [Info] Start training from score -0.218968\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 717\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000500 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445476 -> initscore=-0.218968\n",
      "[LightGBM] [Info] Start training from score -0.218968\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 718\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445131 -> initscore=-0.220362\n",
      "[LightGBM] [Info] Start training from score -0.220362\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 718\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445131 -> initscore=-0.220362\n",
      "[LightGBM] [Info] Start training from score -0.220362\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 718\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000504 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445131 -> initscore=-0.220362\n",
      "[LightGBM] [Info] Start training from score -0.220362\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 733, number of negative: 883\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000781 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1616, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.453589 -> initscore=-0.186179\n",
      "[LightGBM] [Info] Start training from score -0.186179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:18] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:18] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:19] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 586, number of negative: 706\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1292, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.453560 -> initscore=-0.186295\n",
      "[LightGBM] [Info] Start training from score -0.186295\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 587, number of negative: 706\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000725 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.453983 -> initscore=-0.184590\n",
      "[LightGBM] [Info] Start training from score -0.184590\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 587, number of negative: 706\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000651 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.453983 -> initscore=-0.184590\n",
      "[LightGBM] [Info] Start training from score -0.184590\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 586, number of negative: 707\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.453210 -> initscore=-0.187711\n",
      "[LightGBM] [Info] Start training from score -0.187711\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 586, number of negative: 707\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000798 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.453210 -> initscore=-0.187711\n",
      "[LightGBM] [Info] Start training from score -0.187711\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:20] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 735, number of negative: 882\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000793 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1617, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.454545 -> initscore=-0.182322\n",
      "[LightGBM] [Info] Start training from score -0.182322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:20] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 588, number of negative: 705\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000674 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.454756 -> initscore=-0.181471\n",
      "[LightGBM] [Info] Start training from score -0.181471\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 588, number of negative: 705\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000720 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.454756 -> initscore=-0.181471\n",
      "[LightGBM] [Info] Start training from score -0.181471\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 588, number of negative: 706\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000646 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.454405 -> initscore=-0.182888\n",
      "[LightGBM] [Info] Start training from score -0.182888\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 588, number of negative: 706\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000784 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.454405 -> initscore=-0.182888\n",
      "[LightGBM] [Info] Start training from score -0.182888\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 588, number of negative: 706\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.454405 -> initscore=-0.182888\n",
      "[LightGBM] [Info] Start training from score -0.182888\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 720, number of negative: 897\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000746 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1617, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445269 -> initscore=-0.219805\n",
      "[LightGBM] [Info] Start training from score -0.219805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:22] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:22] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 717\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445476 -> initscore=-0.218968\n",
      "[LightGBM] [Info] Start training from score -0.218968\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 717\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000724 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445476 -> initscore=-0.218968\n",
      "[LightGBM] [Info] Start training from score -0.218968\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 718\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000837 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445131 -> initscore=-0.220362\n",
      "[LightGBM] [Info] Start training from score -0.220362\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 718\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445131 -> initscore=-0.220362\n",
      "[LightGBM] [Info] Start training from score -0.220362\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 718\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445131 -> initscore=-0.220362\n",
      "[LightGBM] [Info] Start training from score -0.220362\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 716, number of negative: 901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000688 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1617, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442795 -> initscore=-0.229825\n",
      "[LightGBM] [Info] Start training from score -0.229825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 573, number of negative: 720\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.443155 -> initscore=-0.228365\n",
      "[LightGBM] [Info] Start training from score -0.228365\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 572, number of negative: 721\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442382 -> initscore=-0.231500\n",
      "[LightGBM] [Info] Start training from score -0.231500\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 573, number of negative: 721\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442813 -> initscore=-0.229753\n",
      "[LightGBM] [Info] Start training from score -0.229753\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 573, number of negative: 721\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000656 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442813 -> initscore=-0.229753\n",
      "[LightGBM] [Info] Start training from score -0.229753\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 573, number of negative: 721\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000815 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442813 -> initscore=-0.229753\n",
      "[LightGBM] [Info] Start training from score -0.229753\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 720, number of negative: 897\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000694 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1617, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445269 -> initscore=-0.219805\n",
      "[LightGBM] [Info] Start training from score -0.219805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 717\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000718 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445476 -> initscore=-0.218968\n",
      "[LightGBM] [Info] Start training from score -0.218968\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 717\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000778 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445476 -> initscore=-0.218968\n",
      "[LightGBM] [Info] Start training from score -0.218968\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 718\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445131 -> initscore=-0.220362\n",
      "[LightGBM] [Info] Start training from score -0.220362\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 718\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445131 -> initscore=-0.220362\n",
      "[LightGBM] [Info] Start training from score -0.220362\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 718\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000689 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445131 -> initscore=-0.220362\n",
      "[LightGBM] [Info] Start training from score -0.220362\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 733, number of negative: 883\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000796 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10710\n",
      "[LightGBM] [Info] Number of data points in the train set: 1616, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.453589 -> initscore=-0.186179\n",
      "[LightGBM] [Info] Start training from score -0.186179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 586, number of negative: 706\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10710\n",
      "[LightGBM] [Info] Number of data points in the train set: 1292, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.453560 -> initscore=-0.186295\n",
      "[LightGBM] [Info] Start training from score -0.186295\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 587, number of negative: 706\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000697 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10710\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.453983 -> initscore=-0.184590\n",
      "[LightGBM] [Info] Start training from score -0.184590\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 587, number of negative: 706\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000804 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10710\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.453983 -> initscore=-0.184590\n",
      "[LightGBM] [Info] Start training from score -0.184590\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 586, number of negative: 707\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000724 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10710\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.453210 -> initscore=-0.187711\n",
      "[LightGBM] [Info] Start training from score -0.187711\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 586, number of negative: 707\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000703 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10710\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.453210 -> initscore=-0.187711\n",
      "[LightGBM] [Info] Start training from score -0.187711\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 735, number of negative: 882\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000857 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10710\n",
      "[LightGBM] [Info] Number of data points in the train set: 1617, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.454545 -> initscore=-0.182322\n",
      "[LightGBM] [Info] Start training from score -0.182322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 588, number of negative: 705\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000888 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10710\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.454756 -> initscore=-0.181471\n",
      "[LightGBM] [Info] Start training from score -0.181471\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 588, number of negative: 705\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10710\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.454756 -> initscore=-0.181471\n",
      "[LightGBM] [Info] Start training from score -0.181471\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 588, number of negative: 706\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000778 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10710\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.454405 -> initscore=-0.182888\n",
      "[LightGBM] [Info] Start training from score -0.182888\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 588, number of negative: 706\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000690 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10710\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.454405 -> initscore=-0.182888\n",
      "[LightGBM] [Info] Start training from score -0.182888\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 588, number of negative: 706\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10710\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.454405 -> initscore=-0.182888\n",
      "[LightGBM] [Info] Start training from score -0.182888\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 720, number of negative: 897\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000759 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10710\n",
      "[LightGBM] [Info] Number of data points in the train set: 1617, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445269 -> initscore=-0.219805\n",
      "[LightGBM] [Info] Start training from score -0.219805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 717\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000790 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10710\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445476 -> initscore=-0.218968\n",
      "[LightGBM] [Info] Start training from score -0.218968\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 717\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000793 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10710\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445476 -> initscore=-0.218968\n",
      "[LightGBM] [Info] Start training from score -0.218968\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 718\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000852 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10710\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445131 -> initscore=-0.220362\n",
      "[LightGBM] [Info] Start training from score -0.220362\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 718\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000772 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10710\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445131 -> initscore=-0.220362\n",
      "[LightGBM] [Info] Start training from score -0.220362\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 718\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10710\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445131 -> initscore=-0.220362\n",
      "[LightGBM] [Info] Start training from score -0.220362\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 716, number of negative: 901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000768 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10710\n",
      "[LightGBM] [Info] Number of data points in the train set: 1617, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442795 -> initscore=-0.229825\n",
      "[LightGBM] [Info] Start training from score -0.229825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 573, number of negative: 720\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10710\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.443155 -> initscore=-0.228365\n",
      "[LightGBM] [Info] Start training from score -0.228365\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 572, number of negative: 721\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10710\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442382 -> initscore=-0.231500\n",
      "[LightGBM] [Info] Start training from score -0.231500\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 573, number of negative: 721\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10710\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442813 -> initscore=-0.229753\n",
      "[LightGBM] [Info] Start training from score -0.229753\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 573, number of negative: 721\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000831 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10710\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442813 -> initscore=-0.229753\n",
      "[LightGBM] [Info] Start training from score -0.229753\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 573, number of negative: 721\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000711 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10710\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442813 -> initscore=-0.229753\n",
      "[LightGBM] [Info] Start training from score -0.229753\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 720, number of negative: 897\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000877 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10710\n",
      "[LightGBM] [Info] Number of data points in the train set: 1617, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445269 -> initscore=-0.219805\n",
      "[LightGBM] [Info] Start training from score -0.219805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 717\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000742 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10710\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445476 -> initscore=-0.218968\n",
      "[LightGBM] [Info] Start training from score -0.218968\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 717\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10710\n",
      "[LightGBM] [Info] Number of data points in the train set: 1293, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445476 -> initscore=-0.218968\n",
      "[LightGBM] [Info] Start training from score -0.218968\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 718\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000701 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10710\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445131 -> initscore=-0.220362\n",
      "[LightGBM] [Info] Start training from score -0.220362\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 718\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10710\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445131 -> initscore=-0.220362\n",
      "[LightGBM] [Info] Start training from score -0.220362\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 718\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000806 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10710\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445131 -> initscore=-0.220362\n",
      "[LightGBM] [Info] Start training from score -0.220362\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 906, number of negative: 1115\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000744 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 2021, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.448293 -> initscore=-0.207570\n",
      "[LightGBM] [Info] Start training from score -0.207570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 724, number of negative: 892\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1616, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.448020 -> initscore=-0.208675\n",
      "[LightGBM] [Info] Start training from score -0.208675\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 725, number of negative: 892\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1617, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.448361 -> initscore=-0.207294\n",
      "[LightGBM] [Info] Start training from score -0.207294\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 725, number of negative: 892\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000724 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1617, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.448361 -> initscore=-0.207294\n",
      "[LightGBM] [Info] Start training from score -0.207294\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 725, number of negative: 892\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1617, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.448361 -> initscore=-0.207294\n",
      "[LightGBM] [Info] Start training from score -0.207294\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 725, number of negative: 892\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000697 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1617, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.448361 -> initscore=-0.207294\n",
      "[LightGBM] [Info] Start training from score -0.207294\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "\n",
      "**********************Mejor nmero de componentes principales (n_components): 30\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 906, number of negative: 1115\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000814 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 2021, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.448293 -> initscore=-0.207570\n",
      "[LightGBM] [Info] Start training from score -0.207570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 724, number of negative: 892\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1616, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.448020 -> initscore=-0.208675\n",
      "[LightGBM] [Info] Start training from score -0.208675\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 725, number of negative: 892\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000754 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1617, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.448361 -> initscore=-0.207294\n",
      "[LightGBM] [Info] Start training from score -0.207294\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 725, number of negative: 892\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000728 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1617, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.448361 -> initscore=-0.207294\n",
      "[LightGBM] [Info] Start training from score -0.207294\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 725, number of negative: 892\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1617, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.448361 -> initscore=-0.207294\n",
      "[LightGBM] [Info] Start training from score -0.207294\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 725, number of negative: 892\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000744 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1617, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.448361 -> initscore=-0.207294\n",
      "[LightGBM] [Info] Start training from score -0.207294\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "Caractersticas seleccionadas por PCA:\n",
      "[[ 2.03005224e-03  1.12935750e-03  9.99637354e-01 ...  2.09195348e-05\n",
      "  -1.93164215e-04  8.33620772e-04]\n",
      " [ 5.36999123e-04  5.91219949e-03  7.91721573e-03 ... -1.04305759e-04\n",
      "   6.10071863e-04 -1.22915453e-02]\n",
      " [ 8.35737053e-02 -5.09360863e-03  1.70601956e-02 ... -4.39685388e-04\n",
      "  -9.14865799e-02 -7.98865336e-02]\n",
      " ...\n",
      " [-1.90038950e-02  8.38928860e-02  5.73746840e-04 ...  2.00124542e-07\n",
      "   9.91960891e-03 -4.46945986e-03]\n",
      " [-1.50493640e-02  5.67850941e-02 -8.06290720e-04 ... -2.74779377e-03\n",
      "  -5.15522748e-03 -1.87916176e-02]\n",
      " [-7.41036976e-03  3.66435416e-02 -3.60734374e-04 ... -1.91803990e-02\n",
      "  -6.22152023e-03  9.75033233e-03]]\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 906, number of negative: 1115\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000719 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 2021, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.448293 -> initscore=-0.207570\n",
      "[LightGBM] [Info] Start training from score -0.207570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [01:18:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"feature_fraction\", \"metric\", \"min_child_samples\", \"min_impurity_decrease\", \"min_weight_fraction_leaf\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 724, number of negative: 892\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000695 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1616, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.448020 -> initscore=-0.208675\n",
      "[LightGBM] [Info] Start training from score -0.208675\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 725, number of negative: 892\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000744 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1617, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.448361 -> initscore=-0.207294\n",
      "[LightGBM] [Info] Start training from score -0.207294\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 725, number of negative: 892\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000759 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1617, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.448361 -> initscore=-0.207294\n",
      "[LightGBM] [Info] Start training from score -0.207294\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 725, number of negative: 892\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000788 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1617, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.448361 -> initscore=-0.207294\n",
      "[LightGBM] [Info] Start training from score -0.207294\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 725, number of negative: 892\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000729 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1617, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.448361 -> initscore=-0.207294\n",
      "[LightGBM] [Info] Start training from score -0.207294\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "Caractersticas seleccionadas segn su importancia para la precisin:\n",
      "[('ZONA', nan), ('SITIO', nan), ('EDAD', nan), ('ESCOLARIDAD', nan), ('Ao', nan), ('ESTADO_CIVIL_CASADO', nan), ('ESTADO_CIVIL_DIVORCIADO', nan), ('ESTADO_CIVIL_SOLTERO', nan), ('ESTADO_CIVIL_UNION_LIBRE', nan), ('ESTADO_CIVIL_VIUDO', nan), ('DIA_Domingo', nan), ('DIA_Jueves', nan), ('DIA_Lunes', nan), ('DIA_Martes', nan), ('DIA_Mircoles', nan), ('DIA_Sbado', nan), ('DIA_Viernes', nan), ('TURNO_MADRUGADA', nan), ('TURNO_MAANA', nan), ('TURNO_NOCHE', nan), ('TURNO_TARDE', nan), ('MOVIL_VICTIMA_CONDUCTOR', nan), ('MOVIL_VICTIMA_OTRO', nan), ('MOVIL_VICTIMA_PASAJERO', nan), ('MOVIL_AGRESOR_CONDUCTOR', nan), ('MOVIL_AGRESOR_OTRO', nan), ('MOVIL_AGRESOR_PASAJERO', nan), ('ARMAS_ARMA_BLANCA/CONTUNDENTES', nan), ('ARMAS_ARMAS_DE_FUEGO/TRAUMATICAS', nan), ('ARMAS_OTROS', nan)]\n",
      "Caractersticas seleccionadas segn su importancia para la precisin:\n",
      "Caracterstica 1: ZONA - Importancia: nan\n",
      "Caracterstica 2: SITIO - Importancia: nan\n",
      "Caracterstica 3: EDAD - Importancia: nan\n",
      "Caracterstica 4: ESCOLARIDAD - Importancia: nan\n",
      "Caracterstica 5: Ao - Importancia: nan\n",
      "Caracterstica 6: ESTADO_CIVIL_CASADO - Importancia: nan\n",
      "Caracterstica 7: ESTADO_CIVIL_DIVORCIADO - Importancia: nan\n",
      "Caracterstica 8: ESTADO_CIVIL_SOLTERO - Importancia: nan\n",
      "Caracterstica 9: ESTADO_CIVIL_UNION_LIBRE - Importancia: nan\n",
      "Caracterstica 10: ESTADO_CIVIL_VIUDO - Importancia: nan\n",
      "Caracterstica 11: DIA_Domingo - Importancia: nan\n",
      "Caracterstica 12: DIA_Jueves - Importancia: nan\n",
      "Caracterstica 13: DIA_Lunes - Importancia: nan\n",
      "Caracterstica 14: DIA_Martes - Importancia: nan\n",
      "Caracterstica 15: DIA_Mircoles - Importancia: nan\n",
      "Caracterstica 16: DIA_Sbado - Importancia: nan\n",
      "Caracterstica 17: DIA_Viernes - Importancia: nan\n",
      "Caracterstica 18: TURNO_MADRUGADA - Importancia: nan\n",
      "Caracterstica 19: TURNO_MAANA - Importancia: nan\n",
      "Caracterstica 20: TURNO_NOCHE - Importancia: nan\n",
      "Caracterstica 21: TURNO_TARDE - Importancia: nan\n",
      "Caracterstica 22: MOVIL_VICTIMA_CONDUCTOR - Importancia: nan\n",
      "Caracterstica 23: MOVIL_VICTIMA_OTRO - Importancia: nan\n",
      "Caracterstica 24: MOVIL_VICTIMA_PASAJERO - Importancia: nan\n",
      "Caracterstica 25: MOVIL_AGRESOR_CONDUCTOR - Importancia: nan\n",
      "Caracterstica 26: MOVIL_AGRESOR_OTRO - Importancia: nan\n",
      "Caracterstica 27: MOVIL_AGRESOR_PASAJERO - Importancia: nan\n",
      "Caracterstica 28: ARMAS_ARMA_BLANCA/CONTUNDENTES - Importancia: nan\n",
      "Caracterstica 29: ARMAS_ARMAS_DE_FUEGO/TRAUMATICAS - Importancia: nan\n",
      "Caracterstica 30: ARMAS_OTROS - Importancia: nan\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.6\n",
      "Matriz de Confusin:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative                 285                   4\n",
      "Actual Positive                  23                 194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klgt1\\AppData\\Local\\Temp\\ipykernel_23124\\3908071613.py:86: RuntimeWarning: invalid value encountered in divide\n",
      "  return importances / len(self.models)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mtricas:\n",
      "Accuracy: 0.9466403162055336\n",
      "Precision: 0.9525613275613276\n",
      "Recall: 0.9400841930700174\n",
      "F1 Score: 0.9448568141914391\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Esta ejecutando\")\n",
    "\n",
    "# Clase para el clasificador RandomForest\n",
    "class RandomForest:\n",
    "    def __init__(self, n_estimators, criterion, max_depth, min_samples_split, min_samples_leaf, \n",
    "                 max_features, bootstrap, learning_rate, subsample, colsample_bytree, num_leaves, gamma,\n",
    "                 objective='binary:logistic', max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "                 min_weight_fraction_leaf=0.0, min_child_samples=20, feature_fraction=0.6, metric='logloss'):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.max_features = max_features\n",
    "        self.bootstrap = bootstrap\n",
    "        self.random_state = 42\n",
    "        self.stacking_model = None  \n",
    "        self.predictions = []\n",
    "        self.learning_rate = learning_rate  \n",
    "        self.subsample = subsample  \n",
    "        self.colsample_bytree = colsample_bytree  \n",
    "        self.num_leaves = num_leaves\n",
    "        self.gamma = gamma\n",
    "        self.objective = objective\n",
    "        self.max_leaf_nodes = max_leaf_nodes\n",
    "        self.min_impurity_decrease = min_impurity_decrease\n",
    "        self.min_weight_fraction_leaf = min_weight_fraction_leaf\n",
    "        self.min_child_samples = min_child_samples\n",
    "        self.feature_fraction = feature_fraction\n",
    "        self.metric = metric\n",
    "        self.models = []  # Lista para almacenar los rboles\n",
    "\n",
    "    def fit(self, X, y):        \n",
    "        # Definir el clasificador de nivel 1\n",
    "        estimators = [\n",
    "            ('xgb', XGBClassifier(n_estimators=self.n_estimators, max_depth=self.max_depth, random_state=self.random_state,\n",
    "                                  learning_rate=self.learning_rate, subsample=self.subsample, colsample_bytree=self.colsample_bytree,\n",
    "                                  gamma=self.gamma, objective=self.objective, max_leaf_nodes=self.max_leaf_nodes,\n",
    "                                  min_impurity_decrease=self.min_impurity_decrease, min_weight_fraction_leaf=self.min_weight_fraction_leaf,\n",
    "                                  min_child_samples=self.min_child_samples, feature_fraction=self.feature_fraction, metric=self.metric)),\n",
    "            \n",
    "            ('lgbm', LGBMClassifier(n_estimators=self.n_estimators, max_depth=self.max_depth, random_state=self.random_state,\n",
    "                                    learning_rate=self.learning_rate, subsample=self.subsample, colsample_bytree=self.colsample_bytree,\n",
    "                                    num_leaves=self.num_leaves, max_leaf_nodes=self.max_leaf_nodes,\n",
    "                                    min_child_samples=self.min_child_samples, feature_fraction=self.feature_fraction)),\n",
    "            \n",
    "            ('extra_trees', ExtraTreesClassifier(n_estimators=self.n_estimators, criterion=self.criterion,\n",
    "                                                 max_depth=self.max_depth, min_samples_split=self.min_samples_split,\n",
    "                                                 min_samples_leaf=self.min_samples_leaf, max_features=self.max_features,\n",
    "                                                 bootstrap=self.bootstrap, random_state=self.random_state))]\n",
    "            \n",
    "        # Definir el clasificador de nivel 2 (modelo base)\n",
    "        rf_base = RandomForestClassifier(n_estimators=self.n_estimators, criterion=self.criterion,max_depth=self.max_depth,\n",
    "                                         min_samples_split=self.min_samples_split,min_samples_leaf=self.min_samples_leaf,\n",
    "                                         max_features=self.max_features,bootstrap=self.bootstrap,random_state=self.random_state)\n",
    "        \n",
    "        # Crear el modelo de stacking\n",
    "        self.stacking_model = StackingClassifier(estimators=estimators, final_estimator=rf_base)\n",
    "        self.stacking_model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.stacking_model.predict(X)\n",
    "\n",
    "    def feature_importances(self, X, y):\n",
    "        self.fit(X, y)\n",
    "        importances = np.zeros(X.shape[1])\n",
    "        for tree in self.models:\n",
    "            importances += tree.feature_importances_\n",
    "        return importances / len(self.models)\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {\n",
    "            'n_estimators': self.n_estimators,\n",
    "            'criterion': self.criterion,\n",
    "            'max_depth': self.max_depth,\n",
    "            'min_samples_split': self.min_samples_split,\n",
    "            'min_samples_leaf': self.min_samples_leaf,\n",
    "            'max_features': self.max_features,\n",
    "            'bootstrap': self.bootstrap,\n",
    "            'learning_rate': self.learning_rate,\n",
    "            'subsample': self.subsample,\n",
    "            'colsample_bytree': self.colsample_bytree,\n",
    "            'num_leaves': self.num_leaves,\n",
    "            'gamma': self.gamma,\n",
    "            'objective': self.objective,\n",
    "            'max_leaf_nodes': self.max_leaf_nodes,\n",
    "            'min_impurity_decrease': self.min_impurity_decrease,\n",
    "            'min_weight_fraction_leaf': self.min_weight_fraction_leaf,\n",
    "            'min_child_samples': self.min_child_samples,\n",
    "            'feature_fraction': self.feature_fraction,\n",
    "            'metric': self.metric\n",
    "        }\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        for param, value in params.items():\n",
    "            setattr(self, param, value)\n",
    "        return self\n",
    "\n",
    "# Clase para envolver RandomForest y aplicar PCA\n",
    "\n",
    "class RandomForestClassifierWrapper:\n",
    "    def __init__(self, X, y, feature_names=None, **kwargs):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        self.feature_names = feature_names  \n",
    "        self.kwargs = kwargs\n",
    "        self.rf = RandomForest(**kwargs)\n",
    "        self.selected_features = None\n",
    "\n",
    "    def train(self):        \n",
    "        # Definir el pipeline con PCA y el clasificador RandomForest\n",
    "        pipeline = Pipeline([\n",
    "            ('pca', PCA()),\n",
    "            ('rf', self.rf)\n",
    "        ])\n",
    "    \n",
    "        # Definir los parmetros a ajustar en el grid search\n",
    "        param_grid = {\n",
    "            'pca__n_components': [10, 20, 30, 42]  # Rango de valores de n_components\n",
    "        }\n",
    "    \n",
    "        # Realizar la bsqueda en la grilla con validacin cruzada\n",
    "        grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='precision')\n",
    "        grid_search.fit(self.X_train, self.y_train)\n",
    "    \n",
    "        # Obtener el mejor estimador (pipeline)\n",
    "        best_pipeline = grid_search.best_estimator_\n",
    "        self.rf = best_pipeline.named_steps['rf']\n",
    "    \n",
    "        # Obtener el mejor nmero de componentes principales (n_components)\n",
    "        best_n_components = best_pipeline.named_steps['pca'].n_components\n",
    "        print(\"\\n**********************Mejor nmero de componentes principales (n_components):\", best_n_components)\n",
    "    \n",
    "        # Aplicar PCA con el nmero ptimo de componentes\n",
    "        pca = PCA(n_components=best_n_components)\n",
    "        self.X_train = pca.fit_transform(self.X_train)\n",
    "        self.X_test = pca.transform(self.X_test)\n",
    "    \n",
    "        # Entrenar el modelo RandomForest con los datos transformados\n",
    "        self.rf.fit(self.X_train, self.y_train)\n",
    "    \n",
    "        # Obtener las caractersticas seleccionadas por PCA\n",
    "        selected_features = pca.components_\n",
    "        print(\"Caractersticas seleccionadas por PCA:\")\n",
    "        print(selected_features)\n",
    "    \n",
    "        # Si se proporcionan los nombres de las caractersticas, calcular la importancia de las caractersticas\n",
    "        if self.feature_names is not None:\n",
    "            importances = self.rf.feature_importances(self.X_train, self.y_train)\n",
    "            feature_importance = sorted(zip(self.feature_names, importances), key=lambda x: x[1], reverse=True)\n",
    "            self.selected_features = feature_importance\n",
    "            print(\"Caractersticas seleccionadas segn su importancia para la precisin:\")\n",
    "            print(self.selected_features)\n",
    "\n",
    "\n",
    "    def evaluate(self):\n",
    "        y_pred = self.rf.predict(self.X_test)\n",
    "        accuracy = accuracy_score(self.y_test, y_pred)\n",
    "        precision = precision_score(self.y_test, y_pred, average='macro')\n",
    "        recall = recall_score(self.y_test, y_pred, average='macro')\n",
    "        f1 = f1_score(self.y_test, y_pred, average='macro')\n",
    "\n",
    "        # Calcular la matriz de confusin\n",
    "        conf_matrix = confusion_matrix(self.y_test, y_pred)\n",
    "        # Crear DataFrame para la tabla\n",
    "        df_conf_matrix = pd.DataFrame(conf_matrix, index=['Actual Negative', 'Actual Positive'], columns=['Predicted Negative', 'Predicted Positive'])\n",
    "        \n",
    "        # Mostrar la tabla\n",
    "        print(\"Matriz de Confusin:\")\n",
    "        print(df_conf_matrix)\n",
    "        \n",
    "        # Visualizar la matriz de confusin\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "        plt.xlabel('Predicted labels')\n",
    "        plt.ylabel('True labels')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.show()\n",
    "\n",
    "        # Calcular y graficar la curva ROC\n",
    "        fpr, tpr, _ = roc_curve(self.y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(self.y_test, y_pred)\n",
    "        \n",
    "        plt.figure()\n",
    "        lw = 2\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic (ROC)')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "        \n",
    "        return accuracy, precision, recall, f1\n",
    "\n",
    "    def print_selected_features(self):\n",
    "        if self.selected_features is not None:\n",
    "            print(\"Caractersticas seleccionadas segn su importancia para la precisin:\")\n",
    "            for i, (feature, importance) in enumerate(self.selected_features):\n",
    "                print(f\"Caracterstica {i+1}: {feature} - Importancia: {importance}\")\n",
    "        else:\n",
    "            print(\"No se han seleccionado caractersticas.\")\n",
    "\n",
    "# Leer datos\n",
    "df = pd.read_excel(\"C:\\\\Users\\\\klgt1\\\\Downloads\\\\dataset_BALANCEADO.xlsx\")\n",
    "X = df.drop('CONDUCTA', axis=1)\n",
    "y = df['CONDUCTA']\n",
    "feature_names = X.columns.tolist()  \n",
    "\n",
    "# Leer los parmetros desde el archivo Excel\n",
    "parametros_df = pd.read_excel(\"\\\\Users\\\\klgt1\\\\Downloads\\\\ParametrosOptimizacin.xlsx\")\n",
    "print(parametros_df)\n",
    "# Obtener el primer conjunto de parmetros\n",
    "parametros = parametros_df.iloc[0].to_dict()\n",
    "\n",
    "# Ejecutar el clasificador con los parmetros actuales\n",
    "wrapper = RandomForestClassifierWrapper(X, y, feature_names=feature_names, **parametros)\n",
    "wrapper.train()\n",
    "wrapper.print_selected_features()\n",
    "\n",
    "# Obtener los resultados\n",
    "accuracy, precision, recall, f1_score = wrapper.evaluate()\n",
    "\n",
    "# Imprimir mtricas\n",
    "print(\"Mtricas:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
