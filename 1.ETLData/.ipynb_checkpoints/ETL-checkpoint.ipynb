{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e33eaed7-6201-4b8f-852f-32d89d35f5ca",
   "metadata": {},
   "source": [
    "# Limpieza del conjunto de datos Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8e3970c-98bd-45af-a946-70a35b4a7fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\klgt1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\klgt1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in c:\\users\\klgt1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\klgt1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\klgt1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\klgt1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\klgt1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\klgt1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Enlace para descargar el archivo:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='C:\\Users\\klgt1\\Desktop\\Tesis\\1.ETLData\\datasetClean.xlsx' target='_blank'>C:\\Users\\klgt1\\Desktop\\Tesis\\1.ETLData\\datasetClean.xlsx</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\klgt1\\Desktop\\Tesis\\1.ETLData\\datasetClean.xlsx"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install pandas openpyxl\n",
    "import pandas as pd\n",
    "import os\n",
    "from IPython.display import FileLink \n",
    "\n",
    "class DataProcessor:\n",
    "    def __init__(self, file_name):\n",
    "        self.file_name = file_name\n",
    "        \n",
    "    def load_data(self):\n",
    "        return pd.read_excel(self.file_name)\n",
    "    \n",
    "    def clean_column_names(self, df):    \n",
    "        column_mapping = {\n",
    "            'DESCRIPCION_CONDUCTA': 'CONDUCTA',\n",
    "            'FECHA_HECHO': 'FECHA',\n",
    "            'DIA_SEMANA': 'DIA',\n",
    "            'CLASE_SITIO': 'SITIO',\n",
    "            'ESTADO_CIVIL_PERSONA': 'ESTADO_CIVIL',\n",
    "            'CARGO_PERSONA': 'CARGO',\n",
    "            'GRADO_INSTRUCCION_PERSONA': 'ESCOLARIDAD',\n",
    "            'ARMAS_MEDIOS': 'ARMAS'\n",
    "        }\n",
    "        return df.rename(columns=column_mapping)\n",
    "\n",
    "    def drop_columns(self, df):\n",
    "        df = df.drop(df.index[-1])\n",
    "        columns_to_drop = [\n",
    "            'MUNICIPIO_HECHO',\n",
    "            'BARRIOS_HECHO',\n",
    "            'JURIS.DISTRITO / SECCIONAL',\n",
    "            'JURIS.CAI',\n",
    "            'MES_LARGO',\n",
    "            'AÑO',\n",
    "            'SEMANA_HECHO',\n",
    "            'HORA_HECHO',\n",
    "            'INTERVALOS_HORA',\n",
    "            'DIRECCION_HECHO',\n",
    "            'LATITUD',\n",
    "            'LONGITUD',\n",
    "            'GENERO',\n",
    "            'CLASE_EMPLEADO_DESCRIPCION',\n",
    "            'DEL 01/01/2022 AL 15/11/2022'\n",
    "        ]\n",
    "        return df.drop(columns=columns_to_drop)\n",
    "\n",
    "    def clean_dataset(self, df):\n",
    "        df = self.clean_column_names(df)\n",
    "        df = self.drop_columns(df)\n",
    "        \n",
    "        # Tratar los caracteres especiales de Modalidad\n",
    "        mapeo_modalidad = {'-': 'OTRO' }\n",
    "        df['MODALIDAD'] = df['MODALIDAD'].replace(mapeo_modalidad)\n",
    "\n",
    "        # Limpiar la columna de edad\n",
    "        df['EDAD'] = df['EDAD'].replace('-', pd.NaT)\n",
    "        df['EDAD'] = pd.to_numeric(df['EDAD'], errors='coerce')\n",
    "        promedio_edades = df['EDAD'].mean(skipna=True)\n",
    "        df['EDAD'] = df['EDAD'].fillna(promedio_edades)\n",
    "\n",
    "        # Eliminar caracteres innecesarios de los registros\n",
    "        df['CONDUCTA'] = df['CONDUCTA'].astype(str)\n",
    "        df['CONDUCTA'] = df['CONDUCTA'].apply(lambda x: x.split('.', 1)[-1].strip() if '.' in x else x)\n",
    "\n",
    "        # Convertir la columna de fecha al formato datetime\n",
    "        df['FECHA'] = pd.to_datetime(df['FECHA'], errors='coerce')\n",
    "        # Crear nuevas columnas para mes y año\n",
    "        df['Mes'] = df['FECHA'].dt.month\n",
    "        df['Año'] = df['FECHA'].dt.year\n",
    "\n",
    "        # Eliminar la columna original de fecha si ya no es necesaria\n",
    "        df = df.drop(columns=['FECHA'])\n",
    "        return df\n",
    "\n",
    "    def save_and_download_clean_data(self, df):\n",
    "        try:\n",
    "            # Obtener la ruta del directorio actual\n",
    "            ruta_actual = os.getcwd()\n",
    "            # Concatenar el nombre del archivo de salida al final de la ruta actual\n",
    "            archivo_salida = os.path.join(ruta_actual, 'datasetClean.xlsx')\n",
    "            # Guardar el DataFrame en el archivo Excel en la ruta especificada\n",
    "            df.to_excel(archivo_salida, index=False)\n",
    "            # Crear un enlace para descargar el archivo generado\n",
    "            link = FileLink(archivo_salida)\n",
    "            # Mostrar el enlace para descargar el archivo\n",
    "            print(\"Enlace para descargar el archivo:\")\n",
    "            display(link)\n",
    "        except Exception as e:\n",
    "            print(f\"Error al guardar el archivo: {e}\")\n",
    "\n",
    "\n",
    "    def process_data(self):\n",
    "        # Cargar datos\n",
    "        df = self.load_data()        \n",
    "        # Limpiar datos\n",
    "        df_cleaned = self.clean_dataset(df)        \n",
    "        # Guardar y descargar datos limpios\n",
    "        self.save_and_download_clean_data(df_cleaned)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Obtener la ruta del directorio actual\n",
    "    ruta_actual = os.getcwd()\n",
    "    # Concatenar el nombre del archivo al final de la ruta actual\n",
    "    archivo = os.path.join(ruta_actual, 'violencias 2022.xlsx')\n",
    "    # Instanciar la clase y procesar los datos\n",
    "    processor = DataProcessor(archivo)\n",
    "    processor.process_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af63b6ae-fd59-4009-b5c8-b6a5babc7374",
   "metadata": {},
   "source": [
    "# Transformación de datos del conjunto de datos limpio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01cd56c2-36a9-4e84-a13e-ecdf4c7b34a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: holidays in c:\\users\\klgt1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.43)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\klgt1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from holidays) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\klgt1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil->holidays) (1.16.0)\n",
      "Enlace para descargar el archivo:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='C:\\Users\\klgt1\\Desktop\\Tesis\\1.ETLData\\dataset_Transformado.xlsx' target='_blank'>C:\\Users\\klgt1\\Desktop\\Tesis\\1.ETLData\\dataset_Transformado.xlsx</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\klgt1\\Desktop\\Tesis\\1.ETLData\\dataset_Transformado.xlsx"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install holidays\n",
    "import pandas as pd\n",
    "import os\n",
    "import holidays\n",
    "\n",
    "class DataTransformer:\n",
    "    def __init__(self, file_name):\n",
    "        self.df = pd.read_excel(file_name)\n",
    "    \n",
    "    def transform(self):\n",
    "        self._transform_conducta()\n",
    "        self._transform_zona()\n",
    "        self._transform_one_hot_movil_victima()\n",
    "        self._transform_one_hot_movil_agresor()\n",
    "        self._transform_one_hot_estado_civil()\n",
    "        self._transform_one_hot_dia_semana()\n",
    "        self._transform_one_hot_turno()\n",
    "        self._transform_one_hot_armas()\n",
    "        self._transform_frequency_sitio()\n",
    "        self._transform_one_hot_cargo()\n",
    "        self._transform_one_hot_modalidad()\n",
    "        self._transform_label_encoding_escolaridad()\n",
    "        self._add_special_events()\n",
    "        self._add_holidays()\n",
    "        self._save_data()\n",
    "    \n",
    "    def _transform_conducta(self):\n",
    "        self.df['CONDUCTA'] = self.df['CONDUCTA'].str.strip()\n",
    "        self.df['CONDUCTA'] = self.df['CONDUCTA'].map(lambda x: 1 if x in ['HOMICIDIO', 'FEMINICIDIO',\"ACCESO CARNAL VIOLENTO\",\n",
    "                                                                           \"ACTO SEXUAL VIOLENTO\",\n",
    "                                                                           \"ACCESO CARNAL O ACTO SEXUAL EN PERSONA PUESTA EN INCAPACIDAD DE RESISTIR\",\n",
    "                                                                           \"ACCESO CARNAL ABUSIVO CON MENOR DE 14 AÑOS\",\n",
    "                                                                           \"ACTOS SEXUALES CON MENOR DE 14 AÑOS\",\"ACOSO SEXUAL\",\n",
    "                                                                           \"ACCESO CARNAL O ACTO SEXUAL ABUSIVO CON INCAPAZ DE RESISTIR\"] else 0)\n",
    "    \n",
    "    def _transform_zona(self):        \n",
    "        mapeo_zona = {'RURAL': 0, 'URBANA': 1}\n",
    "        self.df['ZONA'] = self.df['ZONA'].map(mapeo_zona)\n",
    "\n",
    "        \n",
    "    def _transform_one_hot_movil_victima(self):\n",
    "        self.df['MOVIL_VICTIMA'] = self.df['MOVIL_VICTIMA'].replace({'PASAJERO VEHICULO': 'PASAJERO',\n",
    "                                                                 'CONDUCTOR MOTOCICLETA': 'CONDUCTOR',\n",
    "                                                                 'CONDUCTOR VEHICULO': 'CONDUCTOR', 'A PIE': 'OTRO'})\n",
    "        dummies = pd.get_dummies(self.df['MOVIL_VICTIMA'], prefix='MOVIL_VICTIMA', dtype=int)\n",
    "        self.df = pd.concat([self.df, dummies], axis=1)\n",
    "        self.df.drop(columns=['MOVIL_VICTIMA'], inplace=True)    \n",
    "        return self.df\n",
    "\n",
    "    def _transform_one_hot_movil_agresor(self):\n",
    "        self.df['MOVIL_AGRESOR'] = self.df['MOVIL_AGRESOR'].replace({'PASAJERO MOTOCICLETA': 'PASAJERO',\n",
    "                                                                     'CONDUCTOR MOTOCICLETA': 'CONDUCTOR', 'A PIE': 'OTRO'})\n",
    "        dummies = pd.get_dummies(self.df['MOVIL_AGRESOR'], prefix='MOVIL_AGRESOR', dtype=int)\n",
    "        self.df = pd.concat([self.df, dummies], axis=1)\n",
    "        self.df.drop(columns=['MOVIL_AGRESOR'], inplace=True)    \n",
    "        return self.df\n",
    "        \n",
    "    def _transform_one_hot_estado_civil(self):\n",
    "        dummies = pd.get_dummies(self.df['ESTADO_CIVIL'], prefix='ESTADO_CIVIL', dtype=int)\n",
    "        self.df = pd.concat([self.df, dummies], axis=1)\n",
    "        self.df.drop(columns=['ESTADO_CIVIL'], inplace=True)    \n",
    "        return self.df\n",
    "    \n",
    "    def _transform_one_hot_dia_semana(self):\n",
    "        dummies = pd.get_dummies(self.df['DIA'], prefix='DIA', dtype=int)\n",
    "        self.df = pd.concat([self.df, dummies], axis=1)\n",
    "        self.df.drop(columns=['DIA'], inplace=True)    \n",
    "        return self.df\n",
    "    \n",
    "    def _transform_one_hot_turno(self):\n",
    "        self.df['TURNO'] = self.df['TURNO'].replace({'PRIMERO': 'MADRUGADA',\n",
    "                                                     'SEGUNDO': 'MAÑANA',\n",
    "                                                     'TERCERO': 'TARDE',\n",
    "                                                     'CUARTO': 'NOCHE'})\n",
    "        dummies = pd.get_dummies(self.df['TURNO'], prefix='TURNO', dtype=int)\n",
    "        self.df = pd.concat([self.df, dummies], axis=1)\n",
    "        self.df.drop(columns=['TURNO'], inplace=True)    \n",
    "        return self.df\n",
    "\n",
    "\n",
    "    def _transform_one_hot_armas(self):\n",
    "        self.df['ARMAS'] = self.df['ARMAS'].replace({'ARMA DE FUEGO': 'ARMAS DE FUEGO/TRAUMATICAS', 'ARMA TRAUMATICA': 'ARMAS DE FUEGO/TRAUMATICAS',\n",
    "                                                       'ESCOPOLAMINA': 'OTROS','ARMA BLANCA / CORTOPUNZANTE':'ARMA BLANCA/CONTUNDENTES',\n",
    "                                                       'CONTUNDENTES':'ARMA BLANCA/CONTUNDENTES',\n",
    "                                                       'ARTEFACTO EXPLOSIVO/CARGA DINAMITA': 'OTROS','CARRO BOMBA' : 'OTROS','PERRO':'OTROS'})\n",
    "        dummies = pd.get_dummies(self.df['ARMAS'], prefix='ARMAS', dtype=int)\n",
    "        self.df = pd.concat([self.df, dummies], axis=1)\n",
    "        self.df.drop(columns=['ARMAS'], inplace=True)    \n",
    "        return self.df\n",
    "        \n",
    "    def _transform_frequency_sitio(self):\n",
    "        frequency_map = self.df['SITIO'].value_counts(normalize=True).to_dict()\n",
    "        self.df['SITIO'] = self.df['SITIO'].map(frequency_map)\n",
    "        return self.df\n",
    "        \n",
    "    def _transform_one_hot_cargo(self):\n",
    "        self.df['CARGO'] = self.df['CARGO'].replace({'ESTUDIANTE': 'SIN INGRESOS', 'HABITANTE DE LA CALLE': 'SIN INGRESOS',\n",
    "                                                  'AMA DE CASA': 'SIN INGRESOS', 'NO REPORTADO': 'OTROS',\n",
    "                                                  'OFICIOS VARIOS': 'CON INGRESOS', 'VIGILANTE': 'CON INGRESOS',\n",
    "                                                  'MESERO(A)': 'CON INGRESOS', 'AGRICULTOR': 'CON INGRESOS',\n",
    "                                                  'TRABAJADOR SEXUAL': 'CON INGRESOS', 'TECNICO': 'CON INGRESOS',\n",
    "                                                  'ABOGADOS  CLASE 1': 'CON INGRESOS', 'EMPLEADO': 'CON INGRESOS',\n",
    "                                                  'COMERCIANTE': 'CON INGRESOS', 'DOCENTE': 'CON INGRESOS',\n",
    "                                                  'PROMOTOR DE SALUD': 'CON INGRESOS',\n",
    "                                                  'PATRULLERO POLICIA NACIONAL': 'CON INGRESOS',\n",
    "                                                  'ESTILISTA': 'CON INGRESOS', 'INDEPENDIENTE': 'CON INGRESOS'})\n",
    "        dummies = pd.get_dummies(self.df['CARGO'], prefix='CARGO', dtype=int)\n",
    "        self.df = pd.concat([self.df, dummies], axis=1)\n",
    "        self.df.drop(columns=['CARGO'], inplace=True)    \n",
    "        return self.df\n",
    "\n",
    "    def _transform_one_hot_modalidad(self):\n",
    "        self.df['MODALIDAD'] = self.df['MODALIDAD'].replace({'SICARIATO': 'VIOLENCIA FÍSICA', \n",
    "                                                         'SIGNOS DE VIOLENCIA FÍSICA (TORTURA)': 'VIOLENCIA FÍSICA',\n",
    "                                                         'ATRACO': 'VIOLENCIA FÍSICA', \n",
    "                                                         'RIÑAS': 'VIOLENCIA FÍSICA',\n",
    "                                                         'FORCEJEO': 'VIOLENCIA FÍSICA',\n",
    "                                                         'RIÑA O CONFLICTO ENTRE PANDILLAS': 'VIOLENCIA FÍSICA',\n",
    "                                                         'EMPLEO DE SUSTANCIAS TOXICAS': 'VIOLENCIA FÍSICA',\n",
    "                                                         'RIÑA ENTRE COMPAÑEROS PERMANENTES': 'VIOLENCIA INTRAFAMILIAR', \n",
    "                                                         'VIOLENCIA INTRAFAMILIAR': 'VIOLENCIA INTRAFAMILIAR',\n",
    "                                                         'RIÑA ENTRE ESPOSOS': 'VIOLENCIA INTRAFAMILIAR', \n",
    "                                                         'RIÑA HIJO-MADRE': 'VIOLENCIA INTRAFAMILIAR',\n",
    "                                                         'RIÑA ENTRE HIJO-PADRE': 'VIOLENCIA INTRAFAMILIAR',\n",
    "                                                         'RIÑA ENTRE HERMANOS': 'VIOLENCIA INTRAFAMILIAR',\n",
    "                                                         'VIOLENCIA SEXUAL': 'VIOLENCIA SEXUAL', \n",
    "                                                         'AMENAZA/CHANTAJE': 'VIOLENCIA PSICOLOGICA',\n",
    "                                                         'POR AMIGO / CONOCIDO': 'VIOLENCIA PSICOLOGICA', \n",
    "                                                         'POR ESTABLECER': 'OTROS',\n",
    "                                                         'NO REPORTADA': 'OTROS', \n",
    "                                                         'ACCIDENTAL': 'OTROS',\n",
    "                                                         'CREACION DE SITIOS WEB': 'OTROS',\n",
    "                                                         'APLICACIONES': 'OTROS', \n",
    "                                                         'TERRORISMO': 'OTROS',\n",
    "                                                         'OTRO': 'OTROS'})\n",
    "        dummies = pd.get_dummies(self.df['MODALIDAD'], prefix='MODALIDAD', dtype=int)\n",
    "        self.df = pd.concat([self.df, dummies], axis=1)\n",
    "        self.df.drop(columns=['MODALIDAD'], inplace=True)    \n",
    "        return self.df\n",
    "\n",
    "    def _transform_label_encoding_escolaridad(self):\n",
    "        orden_escolaridad = ['ANALFABETA', 'PRIMARIA', 'SECUNDARIA', 'TECNICO', 'TECNOLOGO', 'SUPERIOR', 'NO REPORTADO']\n",
    "        self.df['ESCOLARIDAD'] = self.df['ESCOLARIDAD'].astype(pd.CategoricalDtype(categories=orden_escolaridad, ordered=True)).cat.codes\n",
    "        return self.df\n",
    "    \n",
    "    def _add_special_events(self):\n",
    "        fechas_especiales = pd.to_datetime(['2022-01-06','2022-02-14', '2022-03-08', '2022-05-08', '2022-06-19', '2022-07-20', '2022-09-17','2022-10-31','2022-12-07','2022-12-24'])\n",
    "        fechas_especiales_por_mes = [sum(1 for fecha in fechas_especiales if fecha.month == mes) for mes in range(1, 13)]\n",
    "        self.df['Mes'] = self.df['Mes'].astype(int)\n",
    "        self.df['eventos_especiales_mes'] = self.df['Mes'].apply(lambda mes: 1 if fechas_especiales_por_mes[mes - 1] != 0 else 0)\n",
    "\n",
    "    \n",
    "    def _add_holidays(self):\n",
    "        festivos_colombia = holidays.Colombia(years=2022)\n",
    "        fechas = pd.date_range(start='2022-01-01', end='2022-12-31', freq='D')\n",
    "        festivos_por_mes = [sum(1 for fecha in fechas if fecha in festivos_colombia and fecha.month == mes) for mes in range(1, 13)]\n",
    "        self.df['dias_festivos_mes'] = self.df['Mes'].apply(lambda mes: 1 if festivos_por_mes[mes - 1] != 0 else 0)\n",
    "        self.df = self.df.drop('Mes', axis=1)\n",
    "    \n",
    "    def _save_data(self):\n",
    "        try:\n",
    "            '''self.df.to_excel('dataset_Transformado.xlsx', index=False)\n",
    "            link = FileLink('dataset_Transformado.xlsx')\n",
    "            print(\"Enlace para descargar el archivo:\")\n",
    "            display(link)'''\n",
    "            # Obtener la ruta del directorio actual\n",
    "            ruta_actual = os.getcwd()\n",
    "            \n",
    "            # Concatenar el nombre del archivo de salida al final de la ruta actual\n",
    "            archivo_salida = os.path.join(ruta_actual, 'dataset_Transformado.xlsx')\n",
    "            \n",
    "            # Guardar el DataFrame en el archivo Excel en la ruta especificada\n",
    "            self.df.to_excel(archivo_salida, index=False)\n",
    "            \n",
    "            # Crear un enlace para descargar el archivo generado\n",
    "            link = FileLink(archivo_salida)\n",
    "            \n",
    "            # Mostrar el enlace para descargar el archivo\n",
    "            print(\"Enlace para descargar el archivo:\")\n",
    "            display(link)\n",
    "        except Exception as e:\n",
    "            print(f\"Error al guardar el archivo: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Obtener la ruta del directorio actual\n",
    "    ruta_actual = os.getcwd()\n",
    "    # Concatenar el nombre del archivo al final de la ruta actual\n",
    "    archivo = os.path.join(ruta_actual, 'datasetClean.xlsx')\n",
    "    #transformer = DataTransformer(\"C:\\\\Users\\\\klgt1\\\\Downloads\\\\datasetClean.xlsx\")\n",
    "    transformer = DataTransformer(archivo)\n",
    "    transformer.transform()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2040ca50-6caf-49ac-8ec4-0ac38bc253d9",
   "metadata": {},
   "source": [
    "# Generar conjunto de datos balanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fbb20a6-883c-4d5b-8885-33fac9010fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\klgt1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases equilibradas después de SMOTE: CONDUCTA\n",
      "0    1404\n",
      "1    1123\n",
      "Name: count, dtype: int64\n",
      "Enlace para descargar el archivo:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='C:\\Users\\klgt1\\Desktop\\Tesis\\1.ETLData\\Balanced_Data_Set.xlsx' target='_blank'>C:\\Users\\klgt1\\Desktop\\Tesis\\1.ETLData\\Balanced_Data_Set.xlsx</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\klgt1\\Desktop\\Tesis\\1.ETLData\\Balanced_Data_Set.xlsx"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de variables en el conjunto de datos balanceado: 43\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from IPython.display import display, FileLink\n",
    "import os\n",
    "\n",
    "class DataBalancer:\n",
    "    def __init__(self, dataframe):\n",
    "        self.df = dataframe\n",
    "        \n",
    "    def balance_data(self, minority_class_size=407):\n",
    "        X = self.df.drop('CONDUCTA', axis=1)\n",
    "        y = self.df['CONDUCTA']\n",
    "\n",
    "        n_neighbors_value = min(minority_class_size - 1, 10)\n",
    "        smote = SMOTE(sampling_strategy=0.80, k_neighbors=n_neighbors_value, random_state=42)\n",
    "        X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "        return X_resampled, y_resampled\n",
    "\n",
    "    def save_balanced_data(self, X_resampled, y_resampled, filename='Balanced_Data_Set.xlsx'):\n",
    "        try:\n",
    "            # Obtener la ruta del directorio actual\n",
    "            ruta_actual = os.getcwd()\n",
    "            # Concatenar el nombre del archivo de salida al final de la ruta actual\n",
    "            archivo_salida = os.path.join(ruta_actual, filename)\n",
    "            \n",
    "            X_resampled['CONDUCTA'] = y_resampled\n",
    "            X_resampled.to_excel(archivo_salida, index=False)\n",
    "            link = FileLink(archivo_salida)\n",
    "            print(\"Enlace para descargar el archivo:\")\n",
    "            display(link)\n",
    "        except Exception as e:\n",
    "            print(f\"Error al guardar el archivo: {e}\")\n",
    "\n",
    "    def print_variable_count(self, X_resampled):\n",
    "        print(f\"Número de variables en el conjunto de datos balanceado: {X_resampled.shape[1]}\")\n",
    "\n",
    "    def process_data(self):\n",
    "        # Balancear los datos\n",
    "        X_resampled, y_resampled = self.balance_data()\n",
    "        # Verifica el balance de las clases después del balanceo\n",
    "        print(\"Clases equilibradas después de SMOTE:\", pd.Series(y_resampled).value_counts())\n",
    "        # Guarda el nuevo dataset\n",
    "        self.save_balanced_data(X_resampled, y_resampled)\n",
    "        # Imprime el número de variables\n",
    "        self.print_variable_count(X_resampled)\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    # Obtener la ruta del directorio actual\n",
    "    ruta_actual = os.getcwd()\n",
    "    # Concatenar el nombre del archivo al final de la ruta actual\n",
    "    archivo = os.path.join(ruta_actual, 'dataset_Transformado.xlsx')\n",
    "    # Cargar datos\n",
    "    df = pd.read_excel(archivo)\n",
    "    # Instanciar la clase y procesar los datos\n",
    "    balancer = DataBalancer(df)\n",
    "    balancer.process_data()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
